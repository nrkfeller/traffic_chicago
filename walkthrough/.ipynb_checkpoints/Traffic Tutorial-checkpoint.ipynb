{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Data Analytics Tutorial\n",
    "In this walkthrough, you will use pubsub, dataflow, bigquery and app engine to take data from an API provided by the city of Chicago. And create a service that will allow users to have a global view of Chicago's traffic situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pub/Sub\n",
    "Message-oriented middleware to the cloud. By providing many-to-many, asynchronous messaging that decouples senders and receivers\n",
    "\n",
    "We will grab data from Chicago Traffic API and send it to pub/sub\n",
    "* https://data.cityofchicago.org/Transportation/Chicago-Traffic-Tracker-Congestion-Estimates-by-Se/n4j6-wkkf\n",
    "* https://data.cityofchicago.org/Transportation/Chicago-Traffic-Tracker-Congestion-Estimates-by-Re/t2qc-9pjd\n",
    "\n",
    "First make sure to be logged into a gcloud project\n",
    "```\n",
    "gcloud auth application-default login\n",
    "```\n",
    "\n",
    "Create a topic\n",
    "```\n",
    "gcloud beta pubsub topics create chicagoregions\n",
    "gcloud beta pubsub topics create chicagosegments\n",
    "```\n",
    "\n",
    "Make sure the topics were successfully created\n",
    "![topics](topics.png)\n",
    "Make sure your pubsub service is working\n",
    "```\n",
    "gcloud beta pubsub topics publish chicagoregions \"hello\"\n",
    "gcloud beta pubsub subscriptions create --topic chicagoregions mySub1\n",
    "gcloud beta pubsub subscriptions pull --auto-ack mySub1\n",
    "```\n",
    "\n",
    "If you get the message \"hello\" your subscription is working. \n",
    "You can delete it now\n",
    "```\n",
    "gcloud beta pubsub subscriptions delete mySub1\n",
    "```\n",
    "\n",
    "Create app engine app that GET's the traffic data and sends it to google cloud's pubsub service.\n",
    "```\n",
    "git clone https://github.com/nrkfeller/traffic_chicago\n",
    "```\n",
    "\n",
    "Deploy the service\n",
    "```\n",
    "cd traffic_regions\n",
    "gcloud app deploy app.yaml cron.yaml\n",
    "cd ../traffic_segments\n",
    "gcloud app deploy app.yaml\n",
    "```\n",
    "\n",
    "This should take a few seconds to boot up. Then make sure that messages are actually getting through to the pubsub service.\n",
    "```\n",
    "gcloud beta pubsub subscriptions pull --auto-ack chicagoregions\n",
    "gcloud beta pubsub subscriptions pull --auto-ack chicagosegments\n",
    "```\n",
    "\n",
    "If you see a message with DATA, MESSAGE_ID and ATTRIBUTES, everything is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Bigquery\n",
    "Cheap, scalable data warehouse for ad hoc analysis.\n",
    "\n",
    "What is bigQuery:\n",
    "* Fully managed data warehouse\n",
    "* Fast, petabyte scale SQL like queries\n",
    "* Provides streaming ingest to unbounded data sets\n",
    "* Encrypted durable highly available\n",
    "* Virtually unlimited resources on pay for what you use basis\n",
    "\n",
    "Create a bigquery datasets and tables\n",
    "\n",
    "Go to the url:https://bigquery.cloud.google.com\n",
    "\n",
    "Make sure you are logged in on the right project. Project id should appear in URL\n",
    "\n",
    "Create a Dataset. As in image below. Call it demos\n",
    "![create table](https://cloud.google.com/solutions/images/etlscreenshot-001.png)\n",
    "\n",
    "Create 2 dataset tables. Using the little blue + sign next to your new dataset.\n",
    "* make sure one of them is ```<project id>:demos.regions``` and the other is ```<project id>:demos.segments```\n",
    "\n",
    "You must diligently enter the fields and data types for each column you want to add to your dataset. Make sure the data types are in line with the traffic APIs:\n",
    "* https://data.cityofchicago.org/Transportation/Chicago-Traffic-Tracker-Congestion-Estimates-by-Se/n4j6-wkkf\n",
    "* https://data.cityofchicago.org/Transportation/Chicago-Traffic-Tracker-Congestion-Estimates-by-Se/n4j6-wkkf\n",
    "\n",
    "All done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Dataflow\n",
    "Datalow is a distributed processing backend. Dataflow uses Beam  as a programming model to define and execute data pipelines. Beam pipelines can run on Apex, Fink, Spark or Dataflow. Data can either be streamed of batch (bulk DB migration process) processed. Beam pipelines can be defined in Java and Python.\n",
    "\n",
    "What is dataflow:\n",
    "* Batch or streaming (b-eam)\n",
    "* Unified batch and streaming processing\n",
    "* Fully managed, no ops data processing\n",
    "* Open source programming model (beam)\n",
    "* Intelligently scales to millions of QPS\n",
    "\n",
    "### Connect pubsub to bigquery using dataflow\n",
    "\n",
    "Navigate to the pubsub page in the google cloud console\n",
    "https://console.cloud.google.com/cloudpubsub/\n",
    "\n",
    "Click on the regions topic ```chicagoregions```\n",
    "\n",
    "Find the 'export to bigquery' button\n",
    "![export](export.png)\n",
    "\n",
    "Fill in the export to bigquery form, there are only 2 mandatory fields.\n",
    "* BigQuery table location ```(<project>:<dataset>.<table_name>)``` to write the output to. The tableâ€™s schema must match the input JSON objects.\n",
    "* Temporary Location. Path and filename prefix for writing temporary files. ex: ```gs://<bucket name>/tmp```\n",
    "\n",
    "Navigate to the dataflow tab: https://console.cloud.google.com/dataflow\n",
    "\n",
    "Find your job and click on it.\n",
    "![jobs](jobs.png)\n",
    "\n",
    "And make sure its running. This will take a minute, let it boot up and make sure there are no errors.\n",
    "![running](running.png)\n",
    "\n",
    "Make sure its running; and do the same thing for segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Webapp\n",
    "Setup webapp!\n",
    "\n",
    "Navigate to the webapp directory\n",
    "```\n",
    "cd traffic_chicago/webapp/\n",
    "```\n",
    "\n",
    "Deploy and that's it!\n",
    "```\n",
    "gcloud app deploy\n",
    "```\n",
    "\n",
    "Navigate to the app engine / services tab on your console\n",
    "https://console.cloud.google.com/appengine/services\n",
    "\n",
    "After the deployment is complete click on the webapp service\n",
    "![webapp](webapp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Cool Analytics Visualizations\n",
    "* Google Data Studio to visualize Bigquery data: https://codelabs.developers.google.com/codelabs/cpb104-bigquery-datastudio/#0\n",
    "* Google Datalab to visualize Bigquery data: https://codelabs.developers.google.com/codelabs/cpb100-datalab/index.html?index=..%2F..%2Findex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't Forget to Delete All Services\n",
    "* Pub/sub: https://console.cloud.google.com/cloudpubsub/topicList \n",
    "* All app engine services: https://console.cloud.google.com/appengine/services\n",
    "* Dataflow jobs: https://console.cloud.google.com/dataflow\n",
    "* Bigquery Tables: https://bigquery.cloud.google.com/project/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* Full pipeline (pubsub -> dataflow -> bigquery) : https://www.youtube.com/watch?v=kdmAiQeYGgE\n",
    "* Pub Sub: https://cloud.google.com/pubsub/docs/overview\n",
    "* Dataflow: https://cloud.google.com/dataflow/\n",
    "* BigQuery: https://cloud.google.com/bigquery/\n",
    "* Datastudio: https://www.youtube.com/watch?v=FwpjBp-MgHk\n",
    "* Big data with GCP: https://cloud.google.com/solutions/big-data/stream-analytics/\n",
    "* Apache Beam: https://beam.apache.org/documentation/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
